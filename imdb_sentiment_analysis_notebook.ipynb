{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyP+dwTtGg55msnaq/isIxH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "097d343571dd45d5b10fa11fe60366f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8101e312d20e48418e78fcc085293fa0",
              "IPY_MODEL_e61fb5cb8d744e73b785b6f6d7397fb4",
              "IPY_MODEL_b053debe0e1e41f89f61a9256ff9302a"
            ],
            "layout": "IPY_MODEL_ce8e63ae5a614fc09d0cd2629687b4fc"
          }
        },
        "8101e312d20e48418e78fcc085293fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66b33d3f7314fa7804cb8db78279c24",
            "placeholder": "​",
            "style": "IPY_MODEL_d8e2a622af8e4719b7b0402ce473f3b6",
            "value": "Map: 100%"
          }
        },
        "e61fb5cb8d744e73b785b6f6d7397fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_253b5e44f985466d85b5f7a7857aba47",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e98fe665b6ed457da27e8818004d54a7",
            "value": 25000
          }
        },
        "b053debe0e1e41f89f61a9256ff9302a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecf0bb0353944f98a2d7368b653de909",
            "placeholder": "​",
            "style": "IPY_MODEL_6eff4f1906bc48159e0562efd61b1a4c",
            "value": " 25000/25000 [00:28&lt;00:00, 921.58 examples/s]"
          }
        },
        "ce8e63ae5a614fc09d0cd2629687b4fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66b33d3f7314fa7804cb8db78279c24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e2a622af8e4719b7b0402ce473f3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "253b5e44f985466d85b5f7a7857aba47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98fe665b6ed457da27e8818004d54a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecf0bb0353944f98a2d7368b653de909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eff4f1906bc48159e0562efd61b1a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardo-muniz/IMDB-Sentiment-Analysis/blob/master/imdb_sentiment_analysis_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dJBFitrZX-Vp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d417d6e-e375-4fda-9978-e66fffb1d6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "INxjb022YkCw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_inspect_dataset():\n",
        "  \"\"\"Carrega o dataset IMDB e exibe informações básicas.\"\"\"\n",
        "  print(\"Iniciando o carregamento do dataset IMDB...\")\n",
        "  try:\n",
        "    # Carrega o dataset do Hugging Face\n",
        "    dataset = load_dataset(\"imdb\")\n",
        "\n",
        "    train_data = dataset[\"train\"]\n",
        "    test_data = dataset[\"test\"]\n",
        "\n",
        "    print(f\"Reviews no conjunto de treino: {len(train_data)}\")\n",
        "    print(f\"Reviews no conjunto de teste: {len(test_data)}\")\n",
        "\n",
        "    print(\"\\nCarregamento e inspeção básicos concluídos. Dataset pronto para pré-processamento!\")\n",
        "\n",
        "    return train_data, test_data\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro ao carregar o dataset: {e}\")\n",
        "    return None, None\n"
      ],
      "metadata": {
        "id": "PwIciYD2YljO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = load_and_inspect_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtEyNef4bmOh",
        "outputId": "0251866f-d376-42b7-c537-8c28eabc562c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o carregamento do dataset IMDB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews no conjunto de treino: 25000\n",
            "Reviews no conjunto de teste: 25000\n",
            "\n",
            "Carregamento e inspeção básicos concluídos. Dataset pronto para pré-processamento!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Carregar o tokenizer para um modelo popular de classificação de texto\n",
        "# 'distilbert-base-uncased' é uma boa escolha para começar: leve e eficiente.\n",
        "# 'uncased' significa que o texto será convertido para minúsculas automaticamente.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "print(\"Tokenizer carregado com sucesso!\")\n",
        "print(f\"Exemplo de como o tokenizer funciona para uma frase simples: {tokenizer('Isso é um teste de tokenização.')}\")"
      ],
      "metadata": {
        "id": "JtOSRWLAxmTL",
        "outputId": "32c1700d-c8ed-40c2-a25d-349846e61008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer carregado com sucesso!\n",
            "Exemplo de como o tokenizer funciona para uma frase simples: {'input_ids': [101, 26354, 2080, 1041, 8529, 3231, 2063, 2139, 19204, 21335, 20808, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    # O tokenizer lida com a tokenização, conversão para IDs, e adição de attention_mask.\n",
        "    # truncation=True garante que as sequências mais longas que o limite do modelo sejam cortadas.\n",
        "    # max_length pode ser especificado se você quiser um comprimento máximo diferente do padrão do modelo.\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "# Aplicar a função de pré-processamento aos conjuntos de treino e teste\n",
        "# batched=True processa os exemplos em lotes, o que é mais eficiente.\n",
        "# remove_columns=['text'] remove a coluna de texto original, pois não precisaremos dela mais.\n",
        "# Isso ajuda a economizar memória e focar nas colunas processadas.\n",
        "tokenized_train_data = train_data.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_test_data = test_data.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "print(\"\\nDataset de treino tokenizado:\")\n",
        "print(tokenized_train_data)\n",
        "print(\"\\nDataset de teste tokenizado:\")\n",
        "print(tokenized_test_data)\n",
        "\n",
        "# Você pode inspecionar um exemplo para ver as novas colunas\n",
        "print(\"\\nExemplo de dado tokenizado (primeiro item do treino):\")\n",
        "print(tokenized_train_data[0])"
      ],
      "metadata": {
        "id": "HfoLVPqFyXHS",
        "outputId": "7afe690f-a667-4b54-a5ed-187afb36a72d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "097d343571dd45d5b10fa11fe60366f4",
            "8101e312d20e48418e78fcc085293fa0",
            "e61fb5cb8d744e73b785b6f6d7397fb4",
            "b053debe0e1e41f89f61a9256ff9302a",
            "ce8e63ae5a614fc09d0cd2629687b4fc",
            "a66b33d3f7314fa7804cb8db78279c24",
            "d8e2a622af8e4719b7b0402ce473f3b6",
            "253b5e44f985466d85b5f7a7857aba47",
            "e98fe665b6ed457da27e8818004d54a7",
            "ecf0bb0353944f98a2d7368b653de909",
            "6eff4f1906bc48159e0562efd61b1a4c"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "097d343571dd45d5b10fa11fe60366f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset de treino tokenizado:\n",
            "Dataset({\n",
            "    features: ['label', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 25000\n",
            "})\n",
            "\n",
            "Dataset de teste tokenizado:\n",
            "Dataset({\n",
            "    features: ['label', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 25000\n",
            "})\n",
            "\n",
            "Exemplo de dado tokenizado (primeiro item do treino):\n",
            "{'label': 0, 'input_ids': [101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, ensure 'evaluate' is installed if you haven't already:\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "s9Lg2LYAznt6",
        "outputId": "be45406d-1523-4523-dc68-0e923b140ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "import numpy as np\n",
        "import evaluate # Corrected import\n",
        "\n",
        "# 1. Mapear os rótulos (labels)\n",
        "# O dataset IMDB já tem labels 0 e 1. Para classificação, 0 e 1 são bons.\n",
        "# Podemos renomear a coluna 'label' para 'labels' que é o padrão esperado pelo Trainer.\n",
        "tokenized_train_data = tokenized_train_data.rename_column(\"label\", \"labels\")\n",
        "tokenized_test_data = tokenized_test_data.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Definir as colunas que serão usadas no treinamento\n",
        "tokenized_train_data.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "tokenized_test_data.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "\n",
        "# 2. Definir um DataCollator\n",
        "# Este data collator irá dinamicamente padar os batches para o comprimento máximo em cada batch.\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # Corrected typo DataatorCollatorWithPadding to DataCollatorWithPadding\n",
        "print(\"\\nDataCollator com padding definido.\")\n",
        "\n",
        "# 3. Carregar o Modelo\n",
        "# Vamos usar o mesmo modelo que o tokenizer (distilbert-base-uncased) para classificação de sequência.\n",
        "# num_labels=2 porque temos duas classes: positivo e negativo.\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "print(\"\\nModelo DistilBERT para classificação de sequência carregado.\")\n",
        "\n",
        "# 4. Definir métricas de avaliação\n",
        "# Precisamos de uma função para calcular métricas durante o treinamento.\n",
        "# Acurácia é uma boa métrica para classificação.\n",
        "metric = evaluate.load(\"accuracy\") # Corrected: use evaluate.load\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "print(\"Função de métricas de avaliação definida.\")"
      ],
      "metadata": {
        "id": "iwpXWvO6zaYU",
        "outputId": "dda49fed-5f27-4df4-9630-ce20c55705aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataCollator com padding definido.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo DistilBERT para classificação de sequência carregado.\n",
            "Função de métricas de avaliação definida.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Configurar os argumentos de treinamento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",               # Diretório para salvar os resultados do treinamento e checkpoints\n",
        "    num_train_epochs=3,                   # Número de épocas de treinamento (3 é um bom ponto de partida)\n",
        "    per_device_train_batch_size=16,       # Tamanho do batch para treinamento em cada GPU/CPU\n",
        "    per_device_eval_batch_size=16,        # Tamanho do batch para avaliação em cada GPU/CPU\n",
        "    warmup_steps=500,                     # Número de passos para aquecimento da taxa de aprendizado\n",
        "    weight_decay=0.01,                    # Taxa de decaimento de peso para regularização\n",
        "    logging_dir=\"./logs\",                 # Diretório para salvar os logs do TensorBoard\n",
        "    logging_steps=500,                    # Frequência de log dos passos de treinamento\n",
        "    eval_strategy=\"epoch\",                # CORRIGIDO: Avaliar no final de cada época (era evaluation_strategy)\n",
        "    save_strategy=\"epoch\",                # Salvar checkpoint no final de cada época\n",
        "    load_best_model_at_end=True,          # Carregar o melhor modelo com base na métrica de avaliação\n",
        "    metric_for_best_model=\"accuracy\",     # Métrica para determinar o melhor modelo\n",
        "    push_to_hub=False,                    # Não enviar para o Hugging Face Hub neste momento\n",
        ")\n",
        "\n",
        "# 6. Criar e iniciar o Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_data,\n",
        "    eval_dataset=tokenized_test_data,\n",
        "    tokenizer=tokenizer, # É bom passar o tokenizer para que o Trainer saiba como lidar com o padding, mesmo com o data_collator\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\nConfigurações do Trainer concluídas. Iniciando o treinamento...\")\n",
        "\n",
        "# Iniciar o treinamento\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nTreinamento concluído!\")\n",
        "\n",
        "# Você também pode avaliar o modelo no conjunto de teste após o treinamento\n",
        "print(\"\\nAvaliação final no conjunto de teste:\")\n",
        "results = trainer.evaluate()\n",
        "print(results)\n",
        "\n",
        "# Adicionado para salvar o modelo e o tokenizer após o treinamento e avaliação\n",
        "final_model_save_path = \"./my_imdb_sentiment_model\" # Define o caminho para salvar\n",
        "trainer.save_model(final_model_save_path) # Salva o modelo (já o melhor carregado pelo load_best_model_at_end)\n",
        "tokenizer.save_pretrained(final_model_save_path) # Salva o tokenizer junto com o modelo\n",
        "\n",
        "print(f\"\\nModelo e Tokenizer salvos em: {final_model_save_path}\")"
      ],
      "metadata": {
        "id": "OXX5liMS0D0c",
        "outputId": "6d45ae91-8f72-468c-9283-f9489a1584a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-662013283.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configurações do Trainer concluídas. Iniciando o treinamento...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  9/588 00:42 < 58:28, 0.17 it/s, Epoch 0.04/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "\n",
        "# 1. Definir o caminho onde seu modelo e tokenizer foram salvos\n",
        "# Use o mesmo caminho que você definiu em final_model_save_path no código anterior\n",
        "model_load_path = \"./my_imdb_sentiment_model\"\n",
        "\n",
        "# 2. Carregar o tokenizer e o modelo do disco\n",
        "# Isso é crucial para não precisar retreinar toda vez\n",
        "print(f\"Carregando modelo e tokenizer de: {model_load_path}...\")\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(model_load_path)\n",
        "loaded_model = AutoModelForSequenceClassification.from_pretrained(model_load_path)\n",
        "print(\"Modelo e Tokenizer carregados com sucesso!\")\n",
        "\n",
        "# 3. Criar uma pipeline de análise de sentimento\n",
        "# A pipeline abstrai a tokenização e o pós-processamento, tornando a inferência simples.\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\", # Tipo de tarefa\n",
        "    model=loaded_model,   # Seu modelo carregado\n",
        "    tokenizer=loaded_tokenizer # Seu tokenizer carregado\n",
        ")\n",
        "\n",
        "# 4. Dar uma frase (ou uma lista de frases) para o modelo classificar\n",
        "print(\"\\nRealizando previsões...\")\n",
        "\n",
        "frase1 = \"Este filme é uma obra-prima, absolutamente imperdível!\"\n",
        "frase2 = \"Que perda de tempo! O pior filme que vi este ano.\"\n",
        "frase3 = \"É um filme mediano, com alguns momentos bons e outros nem tanto.\"\n",
        "frase4 = \"As atuações são excelentes, mas o roteiro deixa a desejar.\"\n",
        "\n",
        "# Classificar uma única frase\n",
        "results1 = sentiment_pipeline(frase1)\n",
        "print(f\"\\nFrase: '{frase1}'\")\n",
        "# A saída será algo como [{'label': 'LABEL_1', 'score': 0.99...}]\n",
        "# Lembre-se que LABEL_0 é negativo e LABEL_1 é positivo no seu dataset\n",
        "label1 = \"Positivo\" if results1[0]['label'] == 'LABEL_1' else \"Negativo\"\n",
        "print(f\"Sentimento: {label1} (Confiança: {results1[0]['score']:.4f})\")\n",
        "\n",
        "# Classificar múltiplas frases de uma vez (mais eficiente)\n",
        "frases_para_classificar = [frase1, frase2, frase3, frase4]\n",
        "results_batch = sentiment_pipeline(frases_para_classificar)\n",
        "\n",
        "print(\"\\nClassificação de Múltiplas Frases:\")\n",
        "for i, result in enumerate(results_batch):\n",
        "    current_label = \"Positivo\" if result['label'] == 'LABEL_1' else \"Negativo\"\n",
        "    print(f\"Frase: '{frases_para_classificar[i]}'\")\n",
        "    print(f\"Sentimento: {current_label} (Confiança: {result['score']:.4f})\\n\")"
      ],
      "metadata": {
        "id": "1t9hIcgT65Dq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}